{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b92ac51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/sbansal309/miniconda3/envs/tokensmith/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import faiss\n",
    "import pickle\n",
    "from src.tagging import build_tfidf_tags\n",
    "from src.embedder import SentenceTransformer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0e79be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chunks = json.load(open(\"data/chunks/custom_sections.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18302cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "sources = []\n",
    "metadata = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "846aaa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, c in enumerate(all_chunks):\n",
    "\t# has_table = bool(DocumentChunker.TABLE_RE.search(c))\n",
    "\tmeta = {\n",
    "\t\t\"filename\": \"data/chunks/custom_sections.json\",\n",
    "\t\t\"chunk_id\": i,\n",
    "\t\t\"mode\": \"section\",\n",
    "\t\t\"keep_tables\": True,\n",
    "\t\t\"char_len\": len(c['content']),\n",
    "\t\t\"word_len\": len(c['content'].split()),\n",
    "\t\t\"has_table\": False,\n",
    "\t\t# \"section_hints\": headers[:10],  # small header sample\n",
    "\t}\n",
    "\t# if isinstance(strategy, SlidingTokenStrategy):\n",
    "\t# \tmeta[\"max_tokens\"] = strategy.max_tokens\n",
    "\t# \tmeta[\"overlap_tokens\"] = strategy.overlap_tokens\n",
    "\t# \tmeta[\"tokenizer_name\"] = strategy.tokenizer_name\n",
    "\n",
    "\tchunks.append(c['content'])\n",
    "\tsources.append(c['heading'])\n",
    "\tmetadata.append(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e5a412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer, chunk_tags = build_tfidf_tags(\n",
    "    chunks,\n",
    "    ngram_range=(1, 3),\n",
    "    max_features=25000,\n",
    "    min_df=2,\n",
    "    max_df=0.6,\n",
    "    top_k_per_chunk=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26a2a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tags in enumerate(chunk_tags):\n",
    "\tmetadata[i][\"tags\"] = tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b576b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(\"models/Qwen3-Embedding-4B-Q8_0.gguf\", n_ctx=40960, n_threads=16)\n",
    "embeddings = embedder.encode(\n",
    "\tchunks, batch_size=4, show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d689c938",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d5b09be",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_prefix = \"test_custom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f85ad25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index, f\"{out_prefix}.faiss\")\n",
    "with open(f\"{out_prefix}_chunks.pkl\", \"wb\") as f:\n",
    "\tpickle.dump(chunks, f)\n",
    "with open(f\"{out_prefix}_sources.pkl\", \"wb\") as f:\n",
    "\tpickle.dump(sources, f)\n",
    "with open(f\"{out_prefix}_meta.pkl\", \"wb\") as f:\n",
    "\tpickle.dump(metadata, f)\n",
    "\n",
    "# persist tagging artifacts under meta/\n",
    "os.makedirs(\"meta\", exist_ok=True)\n",
    "with open(os.path.join(\"meta\", f\"{out_prefix}_tfidf.pkl\"), \"wb\") as f:\n",
    "\tpickle.dump(vectorizer, f)\n",
    "with open(os.path.join(\"meta\", f\"{out_prefix}_tags.pkl\"), \"wb\") as f:\n",
    "\tpickle.dump(chunk_tags, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tokensmith",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
